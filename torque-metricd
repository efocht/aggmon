#!/usr/bin/python2
##########################################################################
#                                                                        #
#               Copyright (C) 2013 - 2014 NEC HPC Europe.                #
#                                                                        #
#  These coded instructions, statements, and computer programs  contain  #
#  unpublished  proprietary  information of NEC HPC Europe, and are      #
#  are protected by Federal copyright law.  They  may  not be disclosed  #
#  to  third  parties  or copied or duplicated in any form, in whole or  #
#  in part, without the prior written consent of NEC HPC Europe.         #
#                                                                        #
##########################################################################
#
import ConfigParser
import glob
import md5
import os
import re
import shlex
import signal
import subprocess
import socket
import sys
import syslog
import time
import psutil
from metric_store import MongoDBMetricStore, JMetric, NMetric

# Constants
TORQUE_PROC = "pbs_server"
TORQUE_ACCOUNTING_PATH = "/var/spool/torque/server_priv/accounting"
TORQUE_LOG_MARKER = {"A" : "aborted",         # job has been aborted by server
                     "C" : "checkpointed",    # job has been checkpointed and stopped
                     "D" : "deleted",         # job has been deleted
                     "E" : "exited",          # job has exited (either successfully or unsuccessfully)
                     "Q" : "queued",          # job has been submitted/queued
                     "R" : "rerun",           # an attempt to rerun the job has been made
                     "S" : "started",         # an attempt to start the job has been made
                     "T" : "restarted",       # an attempt to restart the job has been made (after checkpointed)
                    }
LOG_LEVELS = {"error"   : syslog.LOG_ERR,
              "warning" : syslog.LOG_WARNING,
              "info"    : syslog.LOG_INFO,
              "debug"   : syslog.LOG_DEBUG,
             }
CONF_FILE = "/etc/torque-metricd.conf"

global tag_file
global tag_new
global acc_log

config_defaults = {"acc_file_dir"  : TORQUE_ACCOUNTING_PATH,
                   "tag_file"      : TORQUE_ACCOUNTING_PATH + "/tag",
                   "max_acc_files" : 7,
                   "log_level"     : "warning",
                   "mongodb_host"  : "localhost",
                   "mongodb_uname" : "",
                   "mongodb_pw"    : "",
                   "include_cpus"  : "False",
                   "call_tagger"   : "False",
                  }

config = ConfigParser.RawConfigParser( config_defaults )
config.add_section( "daemon" )
config.read( CONF_FILE )
log_level = config.get( "daemon", "log_level" )
acc_file_dir = config.get( "daemon", "acc_file_dir" )
tag_file = config.get( "daemon", "tag_file" )
max_acc_files = config.getint( "daemon", "max_acc_files" )
mongodb_host = config.get( "daemon", "mongodb_host" )
mongodb_uname = config.get( "daemon", "mongodb_uname" )
mongodb_pw = config.get( "daemon", "mongodb_pw" )
include_cpus = config.getboolean( "daemon", "include_cpus" )
call_tagger = config.getboolean( "daemon", "call_tagger" )
if call_tagger:
    remote_cmd = shlex.split( config.get("daemon", "tagger_cmd" ) )
    tagger_str = remote_cmd[-1]

try:
    syslog_max_level = LOG_LEVELS[log_level.lower()]
except:
    syslog_max_level = config_defaults["log_level"]
    syslog.syslog( syslog.LOG_WARNING, "unknown log level '%s'! Defaults to '%s'." % (log_level, config_defaults["log_level"]) )

syslog.openlog( "torque-metricd", syslog.LOG_PID, syslog.LOG_DAEMON )
syslog.setlogmask( syslog.LOG_UPTO( syslog_max_level ) ) 

for line in ["config: acc_file_dir = %(acc_file_dir)s",
             "config: tag_file = %(tag_file)s",
             "config: mongodb_host = %(mongodb_host)s",
             "config: log_level = %(log_level)s"]:
    syslog.syslog( syslog.LOG_INFO, line % locals() )

def sig_handler( sig, frame ):
    if tag_new:
        put_tag( tag_file, tag_new, acc_log )
    syslog.syslog( syslog.LOG_INFO, "terminating due to signal %d..." % sig)
    sys.exit( 0 )

def md5sum( s ):
    m = md5.new()
    m.update( s )
    return m.hexdigest()

def pidof( name ):
    try:
        return [p.pid for p in psutil.process_iter() if p.name() == name]
    except:
        # due to changes in psutil
        return [p.pid for p in psutil.process_iter() if p.name == name]

def torque_pid():
    while True:
        pids = pidof( TORQUE_PROC )
        if pids:
            return pids[0]
        syslog.syslog( syslog.LOG_INFO, "waiting for Torque (%s) to start..." % TORQUE_PROC )
        time.sleep( 60 )

def is_file_open( pid, file_name ):
    dir = os.path.join( "/proc", str( pid ), "fd" )
    if not os.path.exists( dir ):
        syslog.syslog( syslog.LOG_WARNING, "%s seems to have terminated!" % TORQUE_PROC )
        return False
    if not os.access( dir, os.R_OK | os.X_OK ):
        syslog.syslog( syslog.LOG_ERR, "no permissions to access: %s! Terminating..." % dir )
        sys.exit( 1 )
    for fds in os.listdir( dir ):
        for fd in fds:
            full_name = os.path.join( dir, fd )
            try:
                file = os.readlink( full_name )
                if file == file_name:
                    return True
            except:
                pass
    return False

def tail( pid, file_name ):
    fd = open( file_name )
    fd.seek( 0, 2 )
    sleep = 0.001
    buf = ""
    eof = False
    while is_file_open( pid, file_name ):
        while not eof:
            # while not at EOF (indicated by readline returning "")
            time.sleep( sleep )
            buf = buf + fd.readline()
            if buf == "":
                eof = True
                if sleep < 1.0:
                    sleep += 0.001
                continue
            sleep = 0.001
            # complete Torque lines always end with "\n"
            if buf[-1] != "\n":#
                eof = False
                continue
            line = buf
            buf = ""
            yield line
        eof = False
    fd.close()

def parse_torque_accounting_log( line ):
    import time
    line = line.strip()
    if not line:
        syslog.syslog( syslog.LOG_WARNING, "ignoring empty line" )
        return None
    try:
        # example header: 08/08/2014 11:32:23;S;50438;<payload>
        comp = line.split( ";", 3 ) 
        assert comp[1] in TORQUE_LOG_MARKER.keys(), "unknown event: '%s'" % comp[1]
        timestamp = int( time.mktime( time.strptime( comp[0], "%m/%d/%Y %H:%M:%S" ) ) )     # log (not job) timestamp (time, T)
        value = TORQUE_LOG_MARKER[comp[1]]                                                  # event type (value, V)
        name = comp[2].replace( ".", "_" )                                                  # jobid (name, N)
        payload = comp[3]                                                                   # attribute set
        host_name = socket.gethostname()                                                    # add local hostname
        metric = JMetric( name=name, source="Torque", time=timestamp, host=host_name, value=value )
    except Exception as e:
        syslog.syslog( syslog.LOG_WARNING, "parsing header (%s) failed: %s" % (str( e ), line[0:30]) )
        return None
    if not payload:
        return metric
    for attr_str in payload.split( " " ):
        # example payload: user=myuname group=sthaber jobname=STDIN queue=workq ctime=1407490338 qtime=1407490338 etime=1407490338 start=1407490343
        #     owner=myuname@sb-master exec_host=<exec_host> Resource_List.ncpus=1 Resource_List.neednodes=1:ppn=1:foo:ghz-2.6:mhz-2601:ddr1866:qlogic
        #     Resource_List.nodect=1 Resource_List.nodes=1:ppn=1:foo:ghz-2.6:mhz-2601:ddr1866:qlogic
        attr_str = attr_str.replace( ".", "_" )
        try:
            k, v = attr_str.split( "=", 1 )
        except Exception as e:
            syslog.syslog( syslog.LOG_WARNING, "event (%s...), failed to parse attributes: '%s'" % (line[0:30], attr_str) )
            return None
        if k in ["ctime", "qtime", "etime", "start", "end"]:
            v = int( v )
        elif k in ["user", "group", "jobname", "queue", "owner"]:
            pass
            # any special treatment here?
        elif k == "exec_host":
            # example exec_host: sabi36/19+sabi36/18+sabi36/17+sabi36/16+sabi36/15+sabi36/14+sabi36/13+sabi36/12+sabi36/11...
            nodes = sorted( list( set( [r.split( "/" )[0] for r in v.split( "+" )] ) ) )
            k = "cnodes"
            if include_cpus:
                cpus = {}
                for n in nodes:
                    cpus[n] = sorted( list( set( [int( r.split( "/", 2 )[1] ) for r in v.split( "+" ) if r.split( "/", 2 )[0] == n] ) ) )
                v = cpus
            else:
                v = nodes
        elif k.startswith( "Resource_List" ): 
            k = k.replace( "Resource_List", "RL" )
        metric[k] = v
    return metric

def get_tag( tag_file ):
    tag = None
    log_file_name = None
    if os.path.isfile( tag_file ):
        try:
            tag, log_file_name = open( tag_file ).read().split( " ", 2 )
        except Exception as e:
            syslog.syslog( syslog.LOG_DEBUG, "failed to read tag file (%s): %s" % (tag_file, str( e )) )
        if tag and log_file_name:
            syslog.syslog( syslog.LOG_DEBUG, "tag file (%s) found: %s %s" % (tag_file, tag, log_file_name) )
        else:
            tag = None
            log_file_name = None
    return tag, log_file_name

def put_tag( tag_file, tag, log_file_name ):
    open( tag_file, "w" ).write( tag + " " + log_file_name )
    syslog.syslog( syslog.LOG_DEBUG, "wrote tag (%s): %s %s" % (tag_file, tag, log_file_name) )

try:
    store = None
    if mongodb_host:
        store = MongoDBMetricStore( host_name=mongodb_host, username=mongodb_uname, password=mongodb_pw )
    else:
        syslog.syslog( syslog.LOG_WARNING, "can't connect to MongoDB! Set mongodb_host in '%s'." % CONf_FILE )
except Exception as e:
    syslog.syslog( syslog.LOG_ERR, "failed to connect to MongoDB (%s)! Terminating..." % str( e ) )
    sys.exit( 1 )

tag_new = None
signal.signal(signal.SIGTERM, sig_handler)
signal.signal(signal.SIGINT, sig_handler)

# import backlog
tag, last_log = get_tag( tag_file )
tag_found = False
file_names = sorted( glob.glob( acc_file_dir + "/[0-9]*" ) )
start = len( file_names ) - max_acc_files if max_acc_files >= 0 else 0
for file_name in file_names[start:]:
    with open( file_name ) as f:
        acc_log = os.path.basename( file_name )
        if last_log and acc_log < last_log:
            continue
        syslog.syslog( syslog.LOG_DEBUG, "importing metrics from: %s" % file_name )
        for line in f:
            tag_new = md5sum( line )
            if not tag or tag_found:
                metric = parse_torque_accounting_log( line )
                if metric:
                    try:
                        store.addMetric( metric )
                        syslog.syslog( syslog.LOG_DEBUG, "stored: %s" % str( metric ) )
                    except Exception as e:
                        syslog.syslog( syslog.LOG_ERR, "failed to store metric: %s" % str( type( e ) ) )
            else:
                if tag_new == tag:
                    tag_found = True
if tag_new:
    put_tag( tag_file, tag_new, acc_log )
    tag_new = None
if tag and not tag_found:
    syslog.syslog( syslog.LOG_WARNING, "tag (%s) not found in any considered acc file (%s)!" % (tag, acc_file_dir) )

# tail current accounting file
while True:
    pid = torque_pid()
    file_names = sorted( glob.glob( acc_file_dir + "/[0-9]*" ) )
    if not file_names:
        syslog.syslog( syslog.LOG_WARNING, "no accounting file found in %s, waiting..." % acc_file_dir )
        time.sleep( 30 )
        continue
    file_name = file_names[-1]
    syslog.syslog( syslog.LOG_INFO, "monitoring acc file: %s" % file_name )
    for line in tail( pid, file_name ):
        acc_log = os.path.basename( file_name )   # placed here due to sudden SIGTERM
        tag_new = md5sum( line )
        metric = parse_torque_accounting_log( line )
        if metric:
            try:
                store.addMetric( metric )
                syslog.syslog( syslog.LOG_DEBUG, "saved: %s" % str( metric ) )
            except Exception as e:
                syslog.syslog( syslog.LOG_ERR, "can't store metric: %s" % str( e ) )
            if not call_tagger:
                continue
            try:
                if metric["value"] in ["started", "restarted"]:
                    # "rerun" is not considered here since it is followed by a "started" event 
                    if isinstance( metric["cnodes"], dict ):
                        regex_str = "RE:^(" + "|".join( metric["cnodes"].keys() ) + ")$"
                    elif isinstance( metric["cnodes"], list ):
                        regex_str = "^(" + "|".join( metric["cnodes"] ) + ")$"
                    tagger_cmd = tagger_str + " --add J %s H \"%s\"" % (metric["name"], regex_str)
                elif metric["value"] in ["aborted", "checkpointed", "deleted", "exited"]:
                    tagger_cmd = tagger_str + " --del J %s" % metric["name"]
                else:
                    continue
                remote_cmd[-1] = tagger_cmd
                r = subprocess.call( remote_cmd )
                if r != 0:
                    syslog.syslog( syslog.LOG_ERR, "calling tagger_cmd (%s) failed!" % " ".join( remote_cmd ) )
            except Exception as e:
                syslog.syslog( syslog.LOG_ERR, "failed to run tagger_cmd: %s" % str( e ) )
